{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from time import localtime, strftime\n",
    "\n",
    "from sklearn import datasets\n",
    "from snntorch import spikegen\n",
    "from snntorch import functional as SF\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "\n",
    "from z3 import *\n",
    "from collections import defaultdict\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename=f\"none_{strftime('%m%d_%H-%M-%S', localtime())}.log\", level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "shuffle = True\n",
    "beta = 0.95\n",
    "num_steps = 25\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "train = False\n",
    "file_name = 'model_iris.pth'\n",
    "\n",
    "\n",
    "def compare(x, y):\n",
    "    xx, yy = int(x.name().split('_')[-1]), int(y.name().split('_')[-1])\n",
    "    return xx-yy\n",
    "\n",
    "\n",
    "num_input = 4\n",
    "num_hidden = 5\n",
    "num_output = 3\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_input, num_hidden, bias=False)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_output, bias=False)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_data = iris.data / iris.data.max(axis=0)\n",
    "iris_targets = iris.target\n",
    "\n",
    "if shuffle:\n",
    "    assert len(iris_data) == len(iris_data)\n",
    "    perm = np.random.permutation(len(iris_data))\n",
    "    iris_data, iris_targets = iris_data[perm], iris_targets[perm]\n",
    "\n",
    "\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "if train:\n",
    "    net = Net()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "    #loss = nn.CrossEntropyLoss()\n",
    "    loss = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "\n",
    "    # Outer training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        iter_counter = 0\n",
    "\n",
    "        # Minibatch training loop\n",
    "        for number in range(len(iris_targets)):\n",
    "            data = torch.tensor(iris_data[number], dtype=torch.float)\n",
    "            #targets = torch.tensor([0 if i != iris_targets[number] else 1 for i in range(max(iris_targets)+1)],dtype=torch.float)\n",
    "            targets = torch.tensor([iris_targets[number]])\n",
    "\n",
    "            # make spike trains\n",
    "            data_spike = spikegen.rate(data, num_steps=num_steps)\n",
    "\n",
    "            # forward pass\n",
    "            net.train()\n",
    "            spk_rec, mem_rec = net(data_spike.view(num_steps, -1))\n",
    "\n",
    "            # initialize the loss & sum over time\n",
    "            loss_val = torch.zeros((1), dtype=torch.float)\n",
    "            for step in range(num_steps):\n",
    "                loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "            # Gradient calculation + weight update\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Store loss history for future plotting\n",
    "            loss_hist.append(loss_val.item())\n",
    "\n",
    "            if counter % 20 == 0:\n",
    "                print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "            counter += 1\n",
    "            iter_counter += 1\n",
    "    # print(\"Saving model.pth\")\n",
    "    logger.info(\"Saving model.pth\")\n",
    "    torch.save(net, file_name)\n",
    "else:\n",
    "    net = torch.load(file_name)\n",
    "    # print(\"Model loaded\")\n",
    "    logger.info(\"Model loaded\")\n",
    "\n",
    "check = True\n",
    "if check:\n",
    "    acc = 0\n",
    "    perm = np.random.permutation(len(iris_data))\n",
    "    test_data, test_targets = torch.tensor(iris_data[perm][:100], dtype=torch.float), torch.tensor(iris_targets[perm][:100])\n",
    "    for i, data in enumerate(test_data):\n",
    "        spike_data = spikegen.rate(data, num_steps=num_steps)\n",
    "        spk_rec, mem_rec = net(spike_data.view(num_steps, -1))\n",
    "        idx = np.argmax(spk_rec.sum(dim=0).detach().numpy())\n",
    "        if idx == test_targets[i]:\n",
    "            #print(f'match for {test_targets[i]}')\n",
    "            acc += 1\n",
    "        else:\n",
    "            #print(f'Not match for {test_targets[i]}')\n",
    "            pass\n",
    "    # print(f'Accuracy of the model : {acc}%')\n",
    "    logger.info(f'Accuracy of the model : {acc}%')\n",
    "\n",
    "# print()\n",
    "logger.info(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$1 \\le t \\le num\\_steps$$\n",
    "$$0 \\le j \\le num\\_layers-1$$\n",
    "$$0 \\le i \\le num\\_nodes-1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMT encoding\n",
    "\n",
    "# take a random input and make it into a spike train\n",
    "layers = [num_input, num_hidden, num_output]\n",
    "spike_indicators = {}\n",
    "for t in range(num_steps):\n",
    "    for j, m in enumerate(layers):\n",
    "        for i in range(m):\n",
    "            spike_indicators[(i, j, t+1)] = Bool(f'x_{i}_{j}_{t+1}')\n",
    "\n",
    "potentials = {}\n",
    "for t in range(num_steps+1):\n",
    "    for j, m in enumerate(layers):\n",
    "        if j == 0:\n",
    "            continue\n",
    "        for i in range(m):\n",
    "            potentials[(i, j, t)] = Real(f'P_{i}_{j}_{t}')\n",
    "\n",
    "weights = defaultdict(float)\n",
    "w1 = net.fc1.weight\n",
    "for j in range(len(w1)):\n",
    "    for i in range(len(w1[j])):\n",
    "        weights[(i, j, 0)] = float(w1[j][i])\n",
    "w2 = net.fc2.weight\n",
    "for j in range(len(w2)):\n",
    "    for i in range(len(w2[j])):\n",
    "        weights[(i, j, 1)] = float(w2[j][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\epsilon_0(i,0) \\triangleq (P_{i,0}=0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================\n",
    "# Potential Initializations\n",
    "pot_init = []\n",
    "for j, m in enumerate(layers):\n",
    "    if j == 0:\n",
    "        continue\n",
    "    for i in range(m):\n",
    "        pot_init.append(potentials[(i, j, 0)] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, S means:\n",
    "$$\\epsilon_1(i,t) \\triangleq \\left(S_{i,t}=\\sum_{j\\in inSynapse(N_i)}x_{j,t}\\cdot w_{j,i}\\right)$$\n",
    "but in this code, it has different meaning:\n",
    "$$S = P_{i,j,t-1} + \\sum_{i\\in Layer_{j-1}}x_{i,j-1,t}\\cdot w_{j-1,i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Inputs\n",
    "'''\n",
    "assign = []\n",
    "for i, spikes_t in enumerate(sample_spike):\n",
    "    for j, spike in enumerate(spikes_t):\n",
    "        if spike == 1:\n",
    "            assign.append(spike_indicators[(j, 0, i+1)])\n",
    "        else:\n",
    "            assign.append(Not(spike_indicators[(j, 0, i + 1)]))\n",
    "'''\n",
    "\n",
    "# Node eqn\n",
    "node_eqn = []\n",
    "for t in range(1, num_steps+1):\n",
    "    for j, m in enumerate(layers):\n",
    "        if j == 0:\n",
    "            continue\n",
    "\n",
    "        for i in range(m):\n",
    "            S = sum([spike_indicators[(k, j-1, t)]*weights[(k, i, j-1)] for k in range(layers[j-1])]) + potentials[(i, j, t-1)] # epsilon_1\n",
    "            node_eqn.append(\n",
    "                And(\n",
    "                    Implies(\n",
    "                        S >= 1.0,\n",
    "                        And(spike_indicators[(i, j, t)], potentials[(i, j, t)] == S - 1) # epsilon_2 & epsilon_4\n",
    "                    ),\n",
    "                    Implies(\n",
    "                        S < 1.0,\n",
    "                        And(Not(spike_indicators[(i, j, t)]), potentials[(i, j, t)] == beta*S) # epsilon_3 & epsilon_5\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            #print(f'==========================================================\\nAdded equation {(i,j,t)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#S.push()\n",
    "#print(\"Equations Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -r 3 -n 1\n",
    "num_samples = 15\n",
    "samples = iris_data[np.random.choice(range(len(iris_data)), num_samples)]\n",
    "# print(samples)\n",
    "logger.info(samples)\n",
    "deltas = [1,2,3]\n",
    "\n",
    "delta_v = {d: 0 for d in deltas}\n",
    "\n",
    "for delta in deltas:\n",
    "    avt = 0\n",
    "    for sample_no, sample in enumerate(samples):\n",
    "        sample_spike = spikegen.rate(torch.tensor(sample, dtype=torch.float), num_steps=num_steps)\n",
    "\n",
    "        spk_rec, mem_rec = net(sample_spike.view(num_steps, -1)) # epsilon 1~5\n",
    "        label = int(spk_rec.sum(dim=0).argmax())\n",
    "\n",
    "        S = Solver()\n",
    "        # S.add(assign+node_eqn+pot_init)\n",
    "        S.add(node_eqn + pot_init)\n",
    "\n",
    "        sum_val = []\n",
    "        for timestep, spike_train in enumerate(sample_spike):\n",
    "            for i, spike in enumerate(spike_train.view(num_input)):\n",
    "                if spike == 1:\n",
    "                    sum_val.append(If(spike_indicators[(i, 0, timestep + 1)], 0.0, 1.0))\n",
    "                else:\n",
    "                    sum_val.append(If(spike_indicators[(i, 0, timestep + 1)], 1.0, 0.0))\n",
    "        prop = [sum(sum_val) <= delta]\n",
    "        S.add(prop)\n",
    "        '''\n",
    "        s = [[] for i in range(num_steps)]\n",
    "        sv = [Int(f's_{i + 1}') for i in range(num_steps)]\n",
    "        prop = []\n",
    "        for timestep, spike_train in enumerate(sample_spike):\n",
    "            for i, spike in enumerate(spike_train.view(num_input)):\n",
    "                if spike == 1:\n",
    "                    s[timestep].append(If(spike_indicators[(i, 0, timestep + 1)], 0.0, 1.0))\n",
    "                else:\n",
    "                    s[timestep].append(If(spike_indicators[(i, 0, timestep + 1)], 1.0, 0.0))\n",
    "        prop = [sv[i] == sum(s[i]) for i in range(num_steps)]\n",
    "        prop.append(sum(sv) <= delta)\n",
    "        # print(prop[0])\n",
    "        #print(f\"Inputs Property Done in {time.time() - tx} sec\")\n",
    "        '''\n",
    "\n",
    "        # Output property\n",
    "        #tx = time.time()\n",
    "        op = []\n",
    "        intend_sum = sum([2 * spike_indicators[(label, 2, timestep + 1)] for timestep in range(num_steps)])\n",
    "        for t in range(num_output):\n",
    "            if t != op:\n",
    "                op.append(\n",
    "                    Not(intend_sum > sum([2 * spike_indicators[(t, 2, timestep + 1)] for timestep in range(num_steps)]))\n",
    "                )\n",
    "        #print(f'Output Property Done in {time.time() - tx} sec')\n",
    "        S.add(op)\n",
    "        tx = time.time()\n",
    "        res = S.check()\n",
    "        if str(res) == 'unsat':\n",
    "            delta_v[delta] += 1\n",
    "        else:\n",
    "            '''\n",
    "            sadv = np.zeros((num_steps, num_input), dtype=float)\n",
    "            m = S.model()\n",
    "            for tt in range(num_steps):\n",
    "                for k in range(num_input):\n",
    "                    sadv[tt][k] = 1 if str(m[spike_indicators[(k, 0, tt + 1)]]) == 'True' else 0\n",
    "            print()\n",
    "            '''\n",
    "            pass\n",
    "        del S\n",
    "        tss = time.time()-tx\n",
    "        # print(f'Completed for delta = {delta}, sample = {sample_no} in {tss} sec as {res}')\n",
    "        logger.info(f'Completed for delta = {delta}, sample = {sample_no} in {tss} sec as {res}')\n",
    "        avt = (avt*sample_no + tss)/(sample_no+1)\n",
    "    # print(f'Completed for delta = {delta} with {delta_v[delta]} in avg time {avt} sec')\n",
    "    logger.info(f'Completed for delta = {delta} with {delta_v[delta]} in avg time {avt} sec')\n",
    "\n",
    "\n",
    "'''\n",
    "m = S.model()\n",
    "for k in range(num_output):\n",
    "    names = []\n",
    "    for i in m.decls():\n",
    "        t = i.name().split('_')\n",
    "        if t[0] == 'x' and t[1] == f'{k}' and t[2] == '2':\n",
    "            names.append(i)\n",
    "    for i in sorted(names, key=functools.cmp_to_key(compare)):\n",
    "        print(f'{i}->{m[i]}')\n",
    "    input()\n",
    "    print()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[0.84810127 0.70454545 0.63768116 0.56      ]\n",
    "#  [0.81012658 0.65909091 0.62318841 0.52      ]\n",
    "#  [0.59493671 0.72727273 0.23188406 0.08      ]\n",
    "#  [0.81012658 0.70454545 0.79710145 0.72      ]\n",
    "#  [0.73417722 0.90909091 0.17391304 0.08      ]]\n",
    "# Completed for delta = 1, sample = 0 in 14.663048028945923 sec as unsat\n",
    "# Completed for delta = 1, sample = 1 in 12.401368141174316 sec as unsat\n",
    "# Completed for delta = 1, sample = 2 in 5.447791337966919 sec as sat\n",
    "# Completed for delta = 1, sample = 3 in 18.507969617843628 sec as unsat\n",
    "# Completed for delta = 1, sample = 4 in 1.7792270183563232 sec as sat\n",
    "# Completed for delta = 1 with 3 in avg time 10.559880828857422 sec\n",
    "# Completed for delta = 2, sample = 0 in 140.3936517238617 sec as unsat\n",
    "# Completed for delta = 2, sample = 1 in 113.50293159484863 sec as unsat\n",
    "# Completed for delta = 2, sample = 2 in 4.376917600631714 sec as sat\n",
    "# Completed for delta = 2, sample = 3 in 176.66250610351562 sec as unsat\n",
    "# Completed for delta = 2, sample = 4 in 5.695519208908081 sec as sat\n",
    "# Completed for delta = 2 with 3 in avg time 88.12630524635316 sec\n",
    "\n",
    "# [[0.84810127 0.75       0.82608696 0.84      ]\n",
    "#  [0.87341772 0.70454545 0.71014493 0.6       ]\n",
    "#  [0.62025316 0.68181818 0.20289855 0.08      ]\n",
    "#  [0.6835443  0.77272727 0.24637681 0.08      ]\n",
    "#  [0.84810127 0.75       0.82608696 0.84      ]]\n",
    "# Completed for delta = 1, sample = 0 in 14.801784992218018 sec as unsat\n",
    "# Completed for delta = 1, sample = 1 in 23.08232569694519 sec as unsat\n",
    "# Completed for delta = 1, sample = 2 in 3.397867441177368 sec as sat\n",
    "# Completed for delta = 1, sample = 3 in 3.5608396530151367 sec as sat\n",
    "# Completed for delta = 1, sample = 4 in 13.901467561721802 sec as unsat\n",
    "# Completed for delta = 1 with 3 in avg time 11.748857069015504 sec\n",
    "# Completed for delta = 2, sample = 0 in 148.51121640205383 sec as unsat\n",
    "# Completed for delta = 2, sample = 1 in 175.3392734527588 sec as unsat\n",
    "# Completed for delta = 2, sample = 2 in 17.309494972229004 sec as sat\n",
    "# Completed for delta = 2, sample = 3 in 9.000295877456665 sec as sat\n",
    "# Completed for delta = 2, sample = 4 in 215.17273807525635 sec as unsat\n",
    "# Completed for delta = 2 with 3 in avg time 113.06660375595092 sec\n",
    "\n",
    "# [[0.84810127 0.70454545 0.63768116 0.56      ]\n",
    "#  [0.64556962 0.86363636 0.23188406 0.08      ]\n",
    "#  [0.72151899 0.59090909 0.50724638 0.4       ]\n",
    "#  [0.7721519  0.68181818 0.71014493 0.72      ]\n",
    "#  [0.65822785 0.79545455 0.2173913  0.08      ]]\n",
    "# Completed for delta = 1, sample = 0 in 5.486857891082764 sec as unsat\n",
    "# Completed for delta = 1, sample = 1 in 3.6225576400756836 sec as sat\n",
    "# Completed for delta = 1, sample = 2 in 6.907777786254883 sec as unsat\n",
    "# Completed for delta = 1, sample = 3 in 23.071478366851807 sec as unsat\n",
    "# Completed for delta = 1, sample = 4 in 2.7639522552490234 sec as sat\n",
    "# Completed for delta = 1 with 3 in avg time 8.370524787902832 sec\n",
    "# Completed for delta = 2, sample = 0 in 69.07990288734436 sec as unsat\n",
    "# Completed for delta = 2, sample = 1 in 4.636270523071289 sec as sat\n",
    "# Completed for delta = 2, sample = 2 in 125.48776531219482 sec as unsat\n",
    "# Completed for delta = 2, sample = 3 in 164.04840874671936 sec as unsat\n",
    "# Completed for delta = 2, sample = 4 in 3.0649099349975586 sec as sat\n",
    "# Completed for delta = 2 with 3 in avg time 73.26345148086548 sec\n",
    "\n",
    "# [[0.59493671 0.72727273 0.1884058  0.08      ]\n",
    "#  [0.72151899 0.65909091 0.60869565 0.52      ]\n",
    "#  [0.87341772 0.70454545 0.73913043 0.92      ]\n",
    "#  [0.84810127 0.56818182 0.84057971 0.72      ]\n",
    "#  [0.84810127 0.56818182 0.84057971 0.72      ]]\n",
    "# Completed for delta = 1, sample = 0 in 3.0560102462768555 sec as sat\n",
    "# Completed for delta = 1, sample = 1 in 13.852805137634277 sec as unsat\n",
    "# Completed for delta = 1, sample = 2 in 13.295103311538696 sec as unsat\n",
    "# Completed for delta = 1, sample = 3 in 12.685255527496338 sec as unsat\n",
    "# Completed for delta = 1, sample = 4 in 14.264477968215942 sec as unsat\n",
    "# Completed for delta = 1 with 4 in avg time 11.430730438232422 sec\n",
    "# Completed for delta = 2, sample = 0 in 5.856271982192993 sec as sat\n",
    "# Completed for delta = 2, sample = 1 in 141.2722885608673 sec as unsat\n",
    "# Completed for delta = 2, sample = 2 in 152.6037073135376 sec as unsat\n",
    "# Completed for delta = 2, sample = 3 in 224.26228642463684 sec as unsat\n",
    "# Completed for delta = 2, sample = 4 in 173.3075089454651 sec as unsat\n",
    "# Completed for delta = 2 with 4 in avg time 139.46041264533997 sec\n",
    "\n",
    "# [[0.59493671 0.72727273 0.23188406 0.08      ]\n",
    "#  [0.60759494 0.70454545 0.23188406 0.08      ]\n",
    "#  [0.55696203 0.65909091 0.20289855 0.08      ]\n",
    "#  [0.86075949 0.72727273 0.85507246 0.92      ]\n",
    "#  [0.82278481 0.63636364 0.66666667 0.6       ]]\n",
    "# Completed for delta = 1, sample = 0 in 2.5971052646636963 sec as sat\n",
    "# Completed for delta = 1, sample = 1 in 2.7763209342956543 sec as sat\n",
    "# Completed for delta = 1, sample = 2 in 7.374396562576294 sec as unsat\n",
    "# Completed for delta = 1, sample = 3 in 18.07150101661682 sec as unsat\n",
    "# Completed for delta = 1, sample = 4 in 12.63619089126587 sec as unsat\n",
    "# Completed for delta = 1 with 3 in avg time 8.691102933883666 sec\n",
    "# Completed for delta = 2, sample = 0 in 2.087754249572754 sec as sat\n",
    "# Completed for delta = 2, sample = 1 in 5.385530233383179 sec as sat\n",
    "# Completed for delta = 2, sample = 2 in 3.667649745941162 sec as sat\n",
    "# Completed for delta = 2, sample = 3 in 173.5326235294342 sec as unsat\n",
    "# Completed for delta = 2, sample = 4 in 126.35559725761414 sec as unsat\n",
    "# Completed for delta = 2 with 2 in avg time 62.20583100318909 sec\n",
    "\n",
    "# 8min 47s ± 2min 25s per loop (mean ± std. dev. of 5 runs, 1 loop each)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
